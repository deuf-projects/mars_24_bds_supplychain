{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a4b76d-59d4-4f19-9608-86bc9e720c98",
   "metadata": {},
   "source": [
    "**1. IMPORTER LES LIBRAIRIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3ebafe-aaa4-4553-8e91-9e911284678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Huynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Huynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Huynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "# StopWord\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import PunktSentenceTokenizer, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "\n",
    "# Normalisation lexicale\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import spacy\n",
    "#!python -m spacy download fr_core_news_md\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# Ré-échantillonnage\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Vectorisation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Normalisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train_Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Réduction de dimension\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec68d9-0581-46bb-be43-1d5e2cdd7f18",
   "metadata": {},
   "source": [
    "**2. IMPORTER LE FICHIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20a13a9-c7e4-402d-91f2-bbdfcd375344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73846 entries, 0 to 73845\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   nom               73846 non-null  object        \n",
      " 1   notes             73846 non-null  int64         \n",
      " 2   pays              73846 non-null  object        \n",
      " 3   nbr_avis          73846 non-null  int64         \n",
      " 4   date_publication  73846 non-null  object        \n",
      " 5   date_experience   73846 non-null  datetime64[ns]\n",
      " 6   commentaire       73846 non-null  object        \n",
      " 7   titre             73846 non-null  object        \n",
      " 8   commentaires      73846 non-null  object        \n",
      " 9   ponctuation       73846 non-null  int64         \n",
      " 10  sentiment         73846 non-null  float64       \n",
      " 11  sentiment_labels  73846 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(7)\n",
      "memory usage: 6.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>notes</th>\n",
       "      <th>pays</th>\n",
       "      <th>nbr_avis</th>\n",
       "      <th>date_publication</th>\n",
       "      <th>date_experience</th>\n",
       "      <th>commentaire</th>\n",
       "      <th>titre</th>\n",
       "      <th>commentaires</th>\n",
       "      <th>ponctuation</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GUY PEYRONNENC</td>\n",
       "      <td>5</td>\n",
       "      <td>FR</td>\n",
       "      <td>7</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>commande simple et rapide</td>\n",
       "      <td>commandee simple et rapide</td>\n",
       "      <td>commandee simple et rapide commande simple et ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bernard auge</td>\n",
       "      <td>5</td>\n",
       "      <td>FR</td>\n",
       "      <td>1</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>tres bon service</td>\n",
       "      <td>rapide et simple</td>\n",
       "      <td>rapide et simple tres bon service</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alain bruno</td>\n",
       "      <td>5</td>\n",
       "      <td>FR</td>\n",
       "      <td>3</td>\n",
       "      <td>Mar 26, 2024</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>No comment</td>\n",
       "      <td>Honorable bon suivi !</td>\n",
       "      <td>Honorable bon suivi !</td>\n",
       "      <td>1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Martin Maurice</td>\n",
       "      <td>1</td>\n",
       "      <td>FR</td>\n",
       "      <td>41</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>Cdiscount cautionne l'escroquerie en ce sens o...</td>\n",
       "      <td>Cdiscount cautionne l'escroquerie en ce…</td>\n",
       "      <td>Cdiscount cautionne l'escroquerie en ce… Cdisc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHILIPPE PLENET</td>\n",
       "      <td>5</td>\n",
       "      <td>FR</td>\n",
       "      <td>13</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Simple, rapide, prix raisonnables et €commerce...</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Simple Simple, rapide, prix raisonnables et €c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nom  notes pays  nbr_avis date_publication date_experience  \\\n",
       "0   GUY PEYRONNENC      5   FR         7       2 days ago      2024-04-09   \n",
       "1     bernard auge      5   FR         1       4 days ago      2024-04-07   \n",
       "2      alain bruno      5   FR         3     Mar 26, 2024      2024-03-20   \n",
       "3   Martin Maurice      1   FR        41       2 days ago      2024-04-09   \n",
       "4  PHILIPPE PLENET      5   FR        13      7 hours ago      2024-04-11   \n",
       "\n",
       "                                         commentaire  \\\n",
       "0                          commande simple et rapide   \n",
       "1                                   tres bon service   \n",
       "2                                         No comment   \n",
       "3  Cdiscount cautionne l'escroquerie en ce sens o...   \n",
       "4  Simple, rapide, prix raisonnables et €commerce...   \n",
       "\n",
       "                                      titre  \\\n",
       "0                commandee simple et rapide   \n",
       "1                          rapide et simple   \n",
       "2                     Honorable bon suivi !   \n",
       "3  Cdiscount cautionne l'escroquerie en ce…   \n",
       "4                                    Simple   \n",
       "\n",
       "                                        commentaires  ponctuation  sentiment  \\\n",
       "0  commandee simple et rapide commande simple et ...            0   0.225000   \n",
       "1                  rapide et simple tres bon service            0   0.483333   \n",
       "2                              Honorable bon suivi !            1   0.687500   \n",
       "3  Cdiscount cautionne l'escroquerie en ce… Cdisc...            1   0.450000   \n",
       "4  Simple Simple, rapide, prix raisonnables et €c...            0   0.190000   \n",
       "\n",
       "  sentiment_labels  \n",
       "0          Positif  \n",
       "1          Positif  \n",
       "2          Positif  \n",
       "3          Positif  \n",
       "4          Positif  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs nulles : 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"2. Pre-processing & Feature engineering_1.csv\")\n",
    "# Remettre la variable 'date_experience' au format datetime\n",
    "df['date_experience'] = pd.to_datetime(df['date_experience'])\n",
    "\n",
    "df.info()\n",
    "display(df.head())\n",
    "print(\"Nombre de valeurs nulles :\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d95529-39bd-49c5-9dee-1b497d98f831",
   "metadata": {},
   "source": [
    "**3. PRE-PROCESSING & FEATURE ENGINEERING_2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435c57f-7d15-4c58-ba51-673acf66a093",
   "metadata": {},
   "source": [
    "*1) SUPPRESSION COMMENTAIRES > n MOTS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e0d9ae-6269-4d83-aa0d-826e289ba82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les commentaires de plus de n mots\n",
    "n = 100\n",
    "df['nombre_element'] = df['commentaires'].apply(lambda x: len(x.split()))\n",
    "df = df.drop(df.loc[(df['nombre_element'] > n)].index)\n",
    "\n",
    "### Réinitialiser l'inde\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb191083-59ae-4e34-af3f-35640b4d02fe",
   "metadata": {},
   "source": [
    "*2) SUPPRESSION DES VARIABLES INUTILES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be81ce81-38a0-4fb9-bc4e-46fe7f877019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['notes', 'commentaires', 'ponctuation', 'sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b958173d-2339-4a8c-8146-b6c68bec4ddf",
   "metadata": {},
   "source": [
    "*3) STANDARDISATION DES VARIABLES 'ponctuation' ET 'sentiment'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca701b8-e7d6-4dab-80be-7e745d55a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ponctuation', 'sentiment']\n",
    "sc = StandardScaler()\n",
    "df[cols] = sc.fit_transform(df[cols])\n",
    "df[cols] = sc.transform(df[cols])\n",
    "\n",
    "# Changer le format : 'float64' >>> 'float32' pour contourner un possible problème de mémoire\n",
    "df[cols]  = df[cols].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924bee1-9eb6-4d1a-b925-42eca8d84b56",
   "metadata": {},
   "source": [
    "*4) STOP WORDS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9de4faa9-d144-4c78-8dfc-796b739ad7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mettre le texte en minuscule\n",
    "df[\"commentaires\"] = df[\"commentaires\"].str.lower()\n",
    "\n",
    "# 2. Tokenisation : Scinder les phrases en suite de mot\n",
    "df[\"commentaires\"] = df[\"commentaires\"].apply(word_tokenize)\n",
    "\n",
    "# 3. Appliquer le filtre de stopwords au corpus de texte\n",
    "stop_words = set(stopwords.words('french'))\n",
    "new_stop_words = [\",\", \".\", \"``\", \"@\", \"*\", \"(\", \")\", \"...\", \"!\", \"?\", \"-\", \"_\", \">\", \"<\", \":\", \"/\", \"=\", \"--\", \"©\", \"~\", \";\", \"\\\\\", \"\\\\\\\\\", \"qu'on\", \"m'a\", \"pri\",  \"ca\", \"j'ai\", \"disant\",\"qu'ils\", \"qu'elles\", \"dit\", \"faire\", \"qu'il\", \"qu'elle\",\"en\", \"EN\", \"En\", \".\", \",\", \"Je\", \"c'est\", \"s'est\", 'a', 'à', 'â', 'abord', 'afin', 'ai', 'aie', 'ainsi', 'allaient', 'allons', 'après', 'assez', 'attendu', 'au', 'auquel', 'aura', 'auront', 'autre', 'autres', 'aux', 'auxquelles', 'auxquels', 'avaient', 'avais', 'avait', 'avant', 'avec', 'avoir', 'ayant', 'b', 'bigre', 'boum', 'brrr', 'c', 'ça', 'car', 'ce', 'ceci', 'cela', 'celle', 'celle-ci', 'celle-là', 'celles', 'celles-ci', 'celles-là', 'celui', 'celui-ci', 'celui-là', 'cent', 'certain', 'certaine', 'certaines', 'certains', 'certes', 'ces', 'cet', 'cette', 'ceux', 'ceux-ci', 'ceux-là', 'chacun', 'chaque', 'chez', 'chiche','ci', 'cinq', 'cinquantaine', 'cinquante', 'cinquantième', 'cinquième', 'clac', 'clic', 'd', 'da', 'dans', 'de', 'debout', 'des', 'dès', 'desquelles', 'desquels', 'dessous', 'dessus', 'deux', 'deuxième', 'deuxièmement', 'devant', 'devers', 'devra', 'dire', 'dix', 'dix-huit', 'dixième', 'dix-neuf', 'dix-sept', 'douze', 'douzième', 'dring', 'du', 'duquel', 'e', 'elle', 'elle-même', 'elles', 'elles-mêmes', 'en', 'entre', 'envers', 'es', 'ès', 'est', 'et', 'etant', 'étaient', 'étais', 'était', 'étant', 'etc', 'été', 'etre', 'être', 'eux', 'eux-mêmes', 'f', 'fais', 'faisaient', 'faisant', 'fait', 'feront', 'fi', 'flac', 'floc', 'font', 'g', 'gens', 'h', 'huit', 'huitième', 'hum', 'i', 'il', 'ils', 'j', 'je', 'k', 'l', 'la', 'là', 'laquelle', 'las', 'le', 'lequel', 'les', 'lès', 'lesquelles', 'lesquels', 'leur', 'leurs', 'lorsque', 'lui', 'lui-même', 'm', 'ma', 'maint', 'mais', 'me', 'même', 'mêmes', 'mes', 'mien', 'mienne', 'miennes', 'miens', 'mille', 'moi', 'moi-même', 'mon', 'neuf', 'neuvième', 'nos', 'notre', 'nôtre', 'nôtres', 'nous', 'nous-mêmes', 'on', 'ont', 'onze', 'onzième', 'ore', 'ou', 'où', 'outre', 'p', 'paf', 'pan', 'par', 'partant', 'peut', 'peuvent', 'peux','premier', 'première', 'premièrement', 'puisque', 'q', 'qu', 'quanta', 'quant-à-soi', 'quarante', 'quatorze', 'quatre', 'quatre-vingt', 'quatrième', 'quatrièmement', 'que', 'quel', 'quelle', 'quelles', 'quelque', 'quelques', \"quelqu'un\", 'quels', 'qui', 'quiconque', 'quinze', 'quoi', 'quoique', 'r', 'revoici', 'revoilà', 's', 'sa', 'sacrebleu', 'sapristi', 'se', 'seize', 'selon', 'sept', 'septième', 'sera', 'seront', 'ses', 'si', 'sien', 'sienne', 'siennes', 'siens', 'sinon', 'six', 'sixième', 'soi', 'soi-même', 'soit', 'soixante', 'son', 'sont', 'sous', 'suis', 't', 'ta', 'tac', 'te', 'té', 'tel', 'telle', 'telles', 'tels', 'tenant', 'tes', 'tic', 'tien', 'tienne', 'tiennes', 'tiens', 'toc', 'toi', 'toi-même', 'ton', 'treize', 'trente', 'très', 'trois', 'troisième', 'troisièmement', 'tsoin', 'tsouin', 'tu', 'u', 'un', 'une', 'unes', 'uns', 'v', 'va', 'vais', 'vas', 'vé', 'vingt', 'vivat', 'vlan', 'vont', 'vos', 'votre', 'vôtre', 'vôtres', 'vous', 'vous-mêmes', 'vu', 'w', 'x', 'y', 'z', 'devrait', 'dos', 'droite', 'faites', 'haut', 'mine', 'mot', 'nommés', 'parce','voient', 'état', 'étions']\n",
    "# Ajouter à la liste des stopwords, des éléments de syntaxe que nous avons repéré et qui ne servent pas à l'analyse du texte\n",
    "stop_words.update(new_stop_words)\n",
    "# Définir la fonction stop_words_filtering\n",
    "def stop_words_filtering(mots) : \n",
    "    tokens = []\n",
    "    for mot in mots:\n",
    "        if mot not in stop_words:\n",
    "            tokens.append(mot)\n",
    "    return tokens\n",
    "# Appliquer la fonction à la colonne 'commentaires'\n",
    "df[\"commentaires\"] = df[\"commentaires\"].apply(stop_words_filtering)\n",
    "\n",
    "# 4. Reconstitution des phrases après la tokenization\n",
    "for i in range (0, len(df['commentaires'])):\n",
    "    df.loc[i, 'commentaires'] = ' '.join(df.loc[i, 'commentaires'])\n",
    "\n",
    "# 5. Supprimer les regexs identifiés\n",
    "# Regex pour tous les '.', '..', '...', ...\n",
    "for i in range (0, len(df['commentaires'])):\n",
    "    df.loc[i, 'commentaires'] = re.sub(r\"\\.+\", '', df.loc[i, 'commentaires'])\n",
    "# Regex pour tous les chiffres et nombres\n",
    "for i in range (0, len(df['commentaires'])):\n",
    "    df.loc[i, 'commentaires'] = re.sub(r\"[0-9]+\", '', df.loc[i, 'commentaires'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6a9b0-7f41-419d-a813-932e52854cc2",
   "metadata": {},
   "source": [
    "*5) NORMALISATION LEXICALE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9164cb56-2dfc-45f7-a312-b9184877d819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>commentaires</th>\n",
       "      <th>ponctuation</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>commandee simple rapide commande simple rapide</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>-1.112980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>rapide simple tres bon service</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>1.881152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>honorable bon suivi</td>\n",
       "      <td>-0.090812</td>\n",
       "      <td>4.247482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cdiscount cautionne l'escroquerie ce… cdiscoun...</td>\n",
       "      <td>-0.090812</td>\n",
       "      <td>1.494813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>simple simple rapide prix raisonnables €commer...</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>-1.518636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   notes                                       commentaires  ponctuation  \\\n",
       "0      5     commandee simple rapide commande simple rapide    -0.148002   \n",
       "1      5                     rapide simple tres bon service    -0.148002   \n",
       "2      5                                honorable bon suivi    -0.090812   \n",
       "3      1  cdiscount cautionne l'escroquerie ce… cdiscoun...    -0.090812   \n",
       "4      5  simple simple rapide prix raisonnables €commer...    -0.148002   \n",
       "\n",
       "   sentiment  \n",
       "0  -1.112980  \n",
       "1   1.881152  \n",
       "2   4.247482  \n",
       "3   1.494813  \n",
       "4  -1.518636  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f48dde-3240-4461-9f61-dcc136dbf5ee",
   "metadata": {},
   "source": [
    "*a. Lemmatisation (en français)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f52c4e61-c3bf-4016-8690-ae7586f1ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158514e5-f738-4ad1-a085-38cf9b938beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def french_lem(commentaire) :\n",
    "    sortie = []\n",
    "    commentaire = nlp(str(commentaire))\n",
    "    for mot in commentaire :\n",
    "        radical = mot.lemma_\n",
    "        if (radical not in sortie) : sortie.append(radical)\n",
    "    resultat = ' '.join(sortie)\n",
    "    return resultat\n",
    "    \n",
    "df_lem['commentaires'] = df_lem['commentaires'].apply(lambda x : french_lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3721e16-48f5-4f1c-acd9-5489b61aded7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>commentaires</th>\n",
       "      <th>ponctuation</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>commandee simple rapide commande</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>-1.112980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>rapide simple tres bon service</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>1.881152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>honorable bon suivre</td>\n",
       "      <td>-0.090812</td>\n",
       "      <td>4.247482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cdiscount cautionner le escroquerie ce … sens ...</td>\n",
       "      <td>-0.090812</td>\n",
       "      <td>1.494813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>simple rapide prix raisonnable euro commerce f...</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>-1.518636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   notes                                       commentaires  ponctuation  \\\n",
       "0      5                   commandee simple rapide commande    -0.148002   \n",
       "1      5                     rapide simple tres bon service    -0.148002   \n",
       "2      5                               honorable bon suivre    -0.090812   \n",
       "3      1  cdiscount cautionner le escroquerie ce … sens ...    -0.090812   \n",
       "4      5  simple rapide prix raisonnable euro commerce f...    -0.148002   \n",
       "\n",
       "   sentiment  \n",
       "0  -1.112980  \n",
       "1   1.881152  \n",
       "2   4.247482  \n",
       "3   1.494813  \n",
       "4  -1.518636  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification\n",
    "df_lem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5b8c5-b5e3-4350-9708-a300ed4ecb4e",
   "metadata": {},
   "source": [
    "*b. Stemming/Racinisation (en français)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1c3f90-60c4-47fe-8f9f-be39572f245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stem = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02f62a8b-b362-49af-8d09-307636958f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = FrenchStemmer()\n",
    "def stemming(commentaire) :\n",
    "    liste_mots = commentaire.split()\n",
    "    sortie = []\n",
    "    for mot in liste_mots :\n",
    "        radical = stemmer.stem(mot)\n",
    "        if (radical not in sortie) : sortie.append(radical)\n",
    "    resultat = ' '.join(sortie)\n",
    "    return resultat\n",
    "\n",
    "df_stem['commentaires'] = df_stem['commentaires'].apply(lambda x : stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e64de767-93f0-4ad5-9b55-21f21dcf0088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>commentaires</th>\n",
       "      <th>ponctuation</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>commande simpl rapid command</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>-1.112980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>rapid simpl tre bon servic</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>1.881152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>honor bon suivr</td>\n",
       "      <td>-0.090812</td>\n",
       "      <td>4.247482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cdiscount caution le escroquer ce … sen achet ...</td>\n",
       "      <td>-0.090812</td>\n",
       "      <td>1.494813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>simpl rapid prix raison euro commerc franc</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>-1.518636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   notes                                       commentaires  ponctuation  \\\n",
       "0      5                       commande simpl rapid command    -0.148002   \n",
       "1      5                         rapid simpl tre bon servic    -0.148002   \n",
       "2      5                                    honor bon suivr    -0.090812   \n",
       "3      1  cdiscount caution le escroquer ce … sen achet ...    -0.090812   \n",
       "4      5         simpl rapid prix raison euro commerc franc    -0.148002   \n",
       "\n",
       "   sentiment  \n",
       "0  -1.112980  \n",
       "1   1.881152  \n",
       "2   4.247482  \n",
       "3   1.494813  \n",
       "4  -1.518636  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification\n",
    "df_stem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336159d1-9f9e-4f96-9770-23d79d6982b9",
   "metadata": {},
   "source": [
    "*6) VECTORISATION : TF-IDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08ee270f-4336-4bf1-96e2-42996470ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e102db-22c1-4f2e-a073-b99c2daf5bee",
   "metadata": {},
   "source": [
    "*a. Pour la Lemmatisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d18b52c5-04b1-4a0d-9369-401d6ce16765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation Target/Features\n",
    "X_lem = df_lem.drop('notes', axis = 1)\n",
    "y_lem = df_lem['notes']\n",
    "\n",
    "# Train_Test_Split\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07c985fb-50e0-477f-9926-857cd505ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vec_tfidf.fit_transform(X_train_lem['commentaires'])\n",
    "X_test = vec_tfidf.transform(X_test_lem['commentaires'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a373756b-1c4a-49d1-af16-ad261f1df667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.astype('float32').toarray(), index = X_train_lem.index)\n",
    "X_train[cols] = X_train_lem[cols]\n",
    "X_train_lem = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "147a7b8a-652c-4af9-bfd6-41e322da4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test.astype('float32').toarray(), index = X_test_lem.index)\n",
    "X_test[cols] = X_test_lem[cols]\n",
    "X_test_lem = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6027495-9e79-4378-ba2a-fd66754ab413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lem = (55394, 17828)\n",
      "y_train_lem = (55394,)\n",
      "X_test_lem = (13849, 17828)\n",
      "y_test_lem = (13849,)\n"
     ]
    }
   ],
   "source": [
    "# Vérification shape\n",
    "print (\"X_train_lem =\", X_train_lem.shape)\n",
    "print (\"y_train_lem =\", y_train_lem.shape)\n",
    "print (\"X_test_lem =\", X_test_lem.shape)\n",
    "print (\"y_test_lem =\", y_test_lem.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f361c-bd16-4447-a409-1f63c89c8d36",
   "metadata": {},
   "source": [
    "*b. Pour le Stemming*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d6ca781-105e-4c4a-98b5-e11d55c0a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation Target/Features\n",
    "X_stem = df_stem.drop('notes', axis = 1)\n",
    "y_stem = df_stem['notes']\n",
    "\n",
    "# Train_Test_Split\n",
    "X_train_stem, X_test_stem, y_train_stem, y_test_stem = train_test_split(X_stem, y_stem, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e88806b-66aa-4dfa-ab08-c1e5d48d9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vec_tfidf.fit_transform(X_train_stem['commentaires'])\n",
    "X_test = vec_tfidf.transform(X_test_stem['commentaires'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a63d88a-50df-4999-bad2-9e47479d2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.astype('float32').toarray(), index = X_train_stem.index)\n",
    "X_train[cols] = X_train_stem[cols]\n",
    "X_train_stem = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57a3cfb7-8fa1-44f7-9edc-600403083849",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test.astype('float32').toarray(), index = X_test_stem.index)\n",
    "X_test[cols] = X_test_stem[cols]\n",
    "X_test_stem = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e21f55b-3130-4f60-8f25-f12513c06897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_stem = (55394, 17828)\n",
      "y_train_stem = (55394,)\n",
      "X_test_stem = (13849, 17828)\n",
      "y_test_stem = (13849,)\n"
     ]
    }
   ],
   "source": [
    "# Vérification shape\n",
    "print (\"X_train_stem =\", X_train_stem.shape)\n",
    "print (\"y_train_stem =\", y_train_stem.shape)\n",
    "print (\"X_test_stem =\", X_test_stem.shape)\n",
    "print (\"y_test_stem =\", y_test_stem.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206ded9-b80f-4e0c-aaa0-786f683c50fe",
   "metadata": {},
   "source": [
    "*7) REDUCTION DE DIMENSION*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e697f33-c7f3-491b-adc3-f74f3e1c35df",
   "metadata": {},
   "source": [
    "*a. Pour la Lemmatisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5eb0597-63d0-493a-99cf-ff5db5f81185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Supprimer les variables de variance nulle\n",
    "sel = VarianceThreshold(threshold = 1e-4)\n",
    "X_train_lem_rd = sel.fit_transform(X_train_lem)\n",
    "X_test_lem_rd = sel.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8afb69e9-2abe-44cb-8905-bd4e3c75b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lem_rd = (55394, 1101)\n",
      "y_train_lem = (55394,)\n",
      "X_test_lem_rd = (13849, 1101)\n",
      "y_test_lem = (13849,)\n"
     ]
    }
   ],
   "source": [
    "# Vérification shape\n",
    "print (\"X_train_lem_rd =\", X_train_lem_rd.shape)\n",
    "print (\"y_train_lem =\", y_train_lem.shape)\n",
    "print (\"X_test_lem_rd =\", X_test_lem_rd.shape)\n",
    "print (\"y_test_lem =\", y_test_lem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7cb6dec-b2fd-43de-bfa0-d52cb3faf597",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lem_rd = pd.DataFrame(X_train_lem_rd, index = X_train_lem.index)\n",
    "X_test_lem_rd = pd.DataFrame(X_test_lem_rd, index = X_test_lem.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6910c4-9a0b-4890-9c68-94f42ab20af4",
   "metadata": {},
   "source": [
    "*b. Pour le Stemming*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79c62857-e659-472f-9984-0a7ee98babf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les variables de variance nulle\n",
    "sel1 = VarianceThreshold(threshold = 1e-4)\n",
    "X_train_stem_rd = sel1.fit_transform(X_train_stem)\n",
    "X_test_stem_rd = sel1.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e841c6cf-8c0c-4bd5-861e-9e4d1089b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_stem_rd = (55394, 1101)\n",
      "y_train_stem = (55394,)\n",
      "X_test_stem_rd = (13849, 1101)\n",
      "y_test_stem = (13849,)\n"
     ]
    }
   ],
   "source": [
    "# Vérification shape\n",
    "print (\"X_train_stem_rd =\", X_train_stem_rd.shape)\n",
    "print (\"y_train_stem =\", y_train_stem.shape)\n",
    "print (\"X_test_stem_rd =\", X_test_stem_rd.shape)\n",
    "print (\"y_test_stem =\", y_test_stem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e316ff4-c4c6-4eb5-b6a2-efd5615cfa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_rd = pd.DataFrame(X_train_stem_rd, index = X_train_stem.index)\n",
    "X_test_stem_rd = pd.DataFrame(X_test_stem_rd, index = X_test_stem.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1fbc3-5a64-4d16-83c9-e6b97a5a9867",
   "metadata": {},
   "source": [
    "**4. DATAFRAME DANS UN FICHIER .CSV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caffb8ed-aa81-4ba8-9025-7f87b99c8af0",
   "metadata": {},
   "source": [
    "*1) Lemmatisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "472d22be-b677-428f-bb58-e842e1f1c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Lemmatisation (Sans réduction de dimension)\n",
    "# new_df_lem = pd.concat((X_train_lem, X_test_lem))\n",
    "# new_df_lem['y'] = pd.concat((y_train_lem, y_test_lem))\n",
    "# new_df_lem.to_csv(\"4. Lemmatisation_TF-IDF(Sans_Reduction).csv\", index=False)\n",
    "\n",
    "### Nous obtenons des fichiers de plusieurs Giga bien trop compliqués à traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a84b27fa-ae0a-420f-ac51-302c5f5e6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Lemmatisation (Avec Réduction de dimension)\n",
    "new_df_lem_rd = pd.concat((X_train_lem_rd, X_test_lem_rd))\n",
    "new_df_lem_rd['y'] = pd.concat((y_train_lem, y_test_lem))\n",
    "new_df_lem_rd.to_csv(\"4. Lemmatisation_TF-IDF(Avec_Reduction).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a968bae-690c-4163-bf34-4847ea43411e",
   "metadata": {},
   "source": [
    "*2) Stemming*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de806aeb-abe9-486b-8cac-ccc7efa7c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Stemming (Sans réduction de dimension)\n",
    "# new_df_stem = pd.concat((X_train_stem, X_test_stem))\n",
    "# new_df_stem['y'] = pd.concat((y_train_stem, y_test_stem))\n",
    "# new_df_stem.to_csv(\"4. Stemming_TF-IDF(Sans_Reduction).csv\", index=False)\n",
    "\n",
    "### Nous obtenons des fichiers de plusieurs Giga bien trop compliqués à traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a427ca8-6d05-49fa-9e70-e4ddc4049bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Stemming (Avec Réduction de dimension)\n",
    "new_df_stem_rd = pd.concat((X_train_stem_rd, X_test_stem_rd))\n",
    "new_df_stem_rd['y'] = pd.concat((y_train_stem, y_test_stem))\n",
    "new_df_stem_rd.to_csv(\"4. Stemming_TF-IDF(Avec_Reduction).csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
